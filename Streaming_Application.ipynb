{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Geohash\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "from pymongo import MongoClient\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.streaming import StreamingContext\n",
    "from pyspark.streaming.kafka import KafkaUtils\n",
    "import os\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--packages org.apache.spark:spark-streaming-kafka-0-8_2.11:2.3.0 pyspark-shell\"\n",
    "\n",
    "def sendDataToDB(iter):\n",
    "    client = MongoClient()\n",
    "    db = client.fit5148_db\n",
    "    week11 = db.week11\n",
    "    climate_stream = db.climate_stream\n",
    "    \n",
    "    p1, p2, p3 = [], [], []\n",
    "    \n",
    "    for record in iter:\n",
    "        records = json.loads(record[1])\n",
    "        sender_id = records[\"sender_id\"]\n",
    "        if sender_id == \"producer 1\":\n",
    "            p1.append(records)\n",
    "        if sender_id == \"producer 2\":\n",
    "            p2.append(records)\n",
    "        if sender_id == \"producer 3\":\n",
    "            p3.append(records)\n",
    "            \n",
    "    if len(p1) != 0:\n",
    "        for i in range(len(p1)):\n",
    "            tmp = {}\n",
    "            tmp[\"latitude\"] = p1[i][\"latitude\"]\n",
    "            tmp[\"longitude\"] = p1[i][\"longitude\"]\n",
    "            tmp[\"air_temperature_celcius\"] = p1[i][\"air_temperature_celcius\"]\n",
    "            tmp[\"relative_humidity\"] = p1[i][\"relative_humidity\"]\n",
    "            tmp[\"windspeed_knots\"] = p1[i][\"windspeed_knots\"]\n",
    "            tmp[\"max_wind_speed\"] = p1[i][\"max_wind_speed\"]\n",
    "            tmp[\"precipitation\"] = p1[i][\"precipitation\"]\n",
    "            tmp[\"created_time\"] = p1[i][\"created_time\"]\n",
    "            tmp[\"sender_id\"] = p1[i][\"sender_id\"]\n",
    "            climate_stream.insert(tmp)\n",
    "            \n",
    "    p2_inserted = []\n",
    "    p3_inserted = []\n",
    "    if len(p2) != 0 and len(p3) != 0:\n",
    "        for i in range(len(p2)):\n",
    "            for j in range(len(p3)):\n",
    "                if Geohash.encode(p2[i][\"latitude\"], p2[i][\"longitude\"], precision=5) == Geohash.encode(p3[j][\"latitude\"], p3[j][\"longitude\"], precision=5):\n",
    "                    tmp = {}\n",
    "                    tmp[\"latitude\"] = (p2[i][\"latitude\"] + p3[j][\"latitude\"]) / 2\n",
    "                    tmp[\"longitude\"] = (p2[i][\"longitude\"] + p3[j][\"longitude\"]) / 2\n",
    "                    tmp[\"confidence\"] = (p2[i][\"confidence\"] + p3[j][\"confidence\"]) / 2\n",
    "                    tmp[\"surface_temperature_celcius\"] = (p2[i][\"surface_temperature_celcius\"] + p3[j][\"surface_temperature_celcius\"]) / 2\n",
    "                    tmp[\"created_time\"] = {\"producer 2\": p2[i][\"created_time\"], \"producer 3\": p3[j][\"created_time\"]}\n",
    "                    tmp[\"sender\"] = {\"producer 2\": 1, \"producer 3\": 1}\n",
    "                    p2_inserted.append(p2[i])\n",
    "                    p3_inserted.append(p3[j])\n",
    "                    week11.insert(tmp)       \n",
    "     \n",
    "    if len(p2) != 0 and len(p3) == 0:\n",
    "        for i in range(len(p2)):\n",
    "            if p2[i] not in p2_inserted:\n",
    "                tmp = {}\n",
    "                tmp[\"latitude\"] = p2[i][\"latitude\"]\n",
    "                tmp[\"longitude\"] = p2[i][\"longitude\"]\n",
    "                tmp[\"confidence\"] = p2[i][\"confidence\"]\n",
    "                tmp[\"surface_temperature_celcius\"] = p2[i][\"surface_temperature_celcius\"]\n",
    "                tmp[\"created_time\"] = p2[i][\"created_time\"]\n",
    "                tmp[\"sender\"] = {\"producer 3\": 0, \"producer 2\": 1}\n",
    "                week11.insert(tmp)\n",
    "        \n",
    "    if len(p3) != 0 and len(p2) == 0:\n",
    "        for i in range(len(p3)):\n",
    "            if p3[i] not in p3_inserted:\n",
    "                tmp = {}\n",
    "                tmp[\"latitude\"] = p3[i][\"latitude\"]\n",
    "                tmp[\"longitude\"] = p3[i][\"longitude\"]\n",
    "                tmp[\"confidence\"] = p3[i][\"confidence\"]\n",
    "                tmp[\"surface_temperature_celcius\"] = p3[i][\"surface_temperature_celcius\"]\n",
    "                tmp[\"created_time\"] = p3[i][\"created_time\"]\n",
    "                tmp[\"sender\"] = {\"producer 3\": 1, \"producer 2\": 0}\n",
    "                week11.insert(tmp)\n",
    "   \n",
    "    client.close()\n",
    "    \n",
    "\n",
    "n_secs = 10\n",
    "topic = \"Scenario061\"\n",
    "\n",
    "conf = SparkConf().setAppName(\"KafkaStreamProcessor\").setMaster(\"local[2]\")\n",
    "sc = SparkContext.getOrCreate()\n",
    "if sc is None:\n",
    "    sc = SparkContext(conf=conf)\n",
    "sc.setLogLevel(\"WARN\")\n",
    "ssc = StreamingContext(sc, n_secs)\n",
    "    \n",
    "kafkaStream = KafkaUtils.createDirectStream(ssc, [topic], {\n",
    "                        \"bootstrap.servers\":\"127.0.0.1:9092\", \n",
    "                        \"group.id\":\"week11-group\", \n",
    "                        \"fetch.message.max.bytes\":\"15728640\",\n",
    "                        \"auto.offset.reset\":\"largest\"})\n",
    "\n",
    "lines = kafkaStream.foreachRDD(lambda rdd: rdd.foreachPartition(sendDataToDB))\n",
    "\n",
    "ssc.start()\n",
    "time.sleep(600) # Run stream for 10 minutes just in case no detection of producer\n",
    "ssc.stop(stopSparkContext=True, stopGraceFully=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
